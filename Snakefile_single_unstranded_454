# A global singularity image to be used for all jobs - need to specify --use-singularity and have singularity available on the command line
# This image already contains the bioinformatic tools we will be using singularity:
#"file:///shared/.singularity/nextflow-embl-abr-webinar.simg", 
"docker://rsuchecki/nextflow-embl-abr-webinar"



configfile: "config.yaml"

SAMPLES         = config["SAMPLES4"]
READS           = config["READS2"]
ENVS            = config["ENVS"]
REFERENCES      = config["REFERENCES"]
LOGS            = config["LOGS"]
ADAPTERS        = config["ADAPTERS"]
RRNA            = config["RRNA"]
DIR             = config["DIR5"]
RAW             = config["RAW5"]
QC1             = config["QC5_1"]
MULTIQC1        = config["MULTIQC5_1"]
TRIMMED         = config["TRIMMED5"]
QC2             = config["QC5_2"]
MULTIQC2        = config["MULTIQC5_2"]
CLEAN           = config["CLEAN5"]
SUPERCLEAN      = config["SUPERCLEAN"]
SUPERSUPERCLEAN = config["SUPERSUPERCLEAN"]
QC3             = config["QC5_3"]
MULTIQC3        = config["MULTIQC5_3"]
MULTIQC4        = config["MULTIQC5_4"]
MAPPED          = config["MAPPED5"]
MULTIQC5        = config["MULTIQC5_5"]
CUFFLINK        = config["CUFFLINK5"]

################
# Pseudo-rules #
################
# By convention, the first rule should be called "all" and it's "input" defined as
# the list of ALL the files you want the workflow to create. e.g.:
rule all:
	input:
		directory(DIR+"/index"),
		expand(QC1+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS),
		MULTIQC1+"/multiqc_report.html",
		expand(TRIMMED+"/{SAMPLE}_{READ}.fastq.gz", SAMPLE=SAMPLES, READ=READS),
		expand(QC2+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS),
		MULTIQC2+"/multiqc_report.html",
		expand(CLEAN+"/{SAMPLE}_{READ}.fastq.gz", SAMPLE=SAMPLES, READ=READS),
		expand(CLEAN+"/{SAMPLE}_{READ}_stat", SAMPLE=SAMPLES, READ=READS),
		expand(QC3+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS),
		MULTIQC3+"/multiqc_report.html",
		expand(SUPERCLEAN+"/{SAMPLE}_{READ}.fastq.gz", SAMPLE=SAMPLES, READ=READS),
		expand(SUPERCLEAN+"/conta/{SAMPLE}_{READ}.fastq.gz", SAMPLE=SAMPLES, READ=READS),
		expand(SUPERCLEAN+"/{SAMPLE}_{READ}_stat", SAMPLE=SAMPLES, READ=READS),
		SUPERSUPERCLEAN+"/SRR066373_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR066373_R1_stat",
		SUPERSUPERCLEAN+"/SRR1311174_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR1311174_R1_stat",
		SUPERSUPERCLEAN+"/SRR066374_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR066374_R1_stat",
		SUPERSUPERCLEAN+"/SRR1311175_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR1311175_R1_stat",
		SUPERSUPERCLEAN+"/SRR342350_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR342350_R1_stat",
		SUPERSUPERCLEAN+"/SRR342351_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR342351_R1_stat",
		SUPERSUPERCLEAN+"/SRR066375_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR066375_R1_stat",
		SUPERSUPERCLEAN+"/SRR1311176_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR1311176_R1_stat",
		SUPERSUPERCLEAN+"/SRR066376_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR066376_R1_stat",
		SUPERSUPERCLEAN+"/SRR1311177_R1.fastq.gz",
		SUPERSUPERCLEAN+"/SRR1311177_R1_stat",
		expand(MAPPED+"/{SAMPLE}Aligned.sortedByCoord.out.bam", SAMPLE=SAMPLES),
		MULTIQC4+"/multiqc_report.html",
		MULTIQC5+"/multiqc_report.html",
		expand(CUFFLINK+"/{SAMPLE}/transcripts.gtf", SAMPLE=SAMPLES),
		CUFFLINK+"/assemblies.txt",

################
# Rules Proper #
################
rule star_index:
	input:
		REFERENCES+"/Plantago.fasta.gz"
	output:
		directory(DIR+"/index")
	conda:
		ENVS
	log:
		LOGS+"/star_index"
	shell:
		"""
		mkdir {output} &&
		STAR --runThreadN 8 \
		--runMode genomeGenerate \
		--genomeDir {output} \
		--genomeSAindexNbases 12 \
		--genomeFastaFiles {input}
		2> {log}
		"""

rule fastqc_raw:
	input:
		RAW+"/{SAMPLE}.fastq.gz"
	output:
		zip = QC1+"/{SAMPLE}_fastqc.zip",
		html = QC1+"/{SAMPLE}_fastqc.html"
	conda:
		ENVS
	log:
		LOGS+"/fastqc_raw/{SAMPLE}"
	params: 
		QC1
	shell:
		"""
		fastqc -o {params} --threads 2 {input}
		2> {log}
		"""

rule multiqc_raw:
	input:
		expand(QC1+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS)
	output:
		MULTIQC1+"/multiqc_report.html"
	conda:
		ENVS
	log:
		LOGS+"/multiqc_raw/multiqc_report"
	params:
		indir = QC1 ,
		outdir = MULTIQC1
	shell:
		"""
		multiqc {params.indir} -o {params.outdir}
		2> {log}
		"""

rule trimmomatic:
	input:
		r1 = RAW+"/{SAMPLES}_R1.fastq.gz",
		adapters = ADAPTERS
	output:
		TRIMMED+"/{SAMPLES}_R1.fastq.gz",
	conda:
		ENVS
	log:
		LOGS+"/trimmomatic/{SAMPLES}_R1"
	shell:
		"""
		trimmomatic SE -threads 2 {input.r1} {output} ILLUMINACLIP:{input.adapters}:2:30:10:3:true LEADING:2 TRAILING:2 SLIDINGWINDOW:4:15 MINLEN:36 \
		> {log}
		"""

rule fastqc_trimmed:
	input:
		TRIMMED+"/{SAMPLE}.fastq.gz"
	output:
		zip = QC2+"/{SAMPLE}_fastqc.zip",
		html = QC2+"/{SAMPLE}_fastqc.html"
	conda:
		ENVS
	log:
		LOGS+"/fastqc_trimmed/{SAMPLE}"
	params:
		QC2
	shell:
		"""
		fastqc -o {params} --threads 2 {input}
		2> {log}
		"""

rule multiqc_trimmed:
	input:
		expand(QC2+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS)
	output:
		MULTIQC2+"/multiqc_report.html"
	conda:
		ENVS
	log:
		LOGS+"/multiqc_trimmed/multiqc_report"
	params:
		indir = QC2 ,
		outdir = MULTIQC2
	shell:
		"""
		multiqc {params.indir} -o {params.outdir} 
		2> {log}
		"""

rule bbmap:
	input:
		file = TRIMMED+"/{SAMPLES}_R1.fastq.gz",
		ref1 = RRNA+"/SILVA_128_LSURef_tax_silva.fasta",
		ref2 = RRNA+"/SILVA_138_SSURef_NR99_tax_silva.fasta",
		ref3 = RRNA+"/SILVA_138_SSURef_tax_silva.fasta",
		ref4 = REFERENCES+"/plantago_chloroplast.fasta",
		ref5 = REFERENCES+"/plantago_mitocondria.fasta",
		ref6 = REFERENCES+"/NC_041421.1.fasta",
		ref7 = RRNA+"/Archaea.fasta",
		ref8 = RRNA+"/Bacteria.fasta",
		ref9 = RRNA+"/Mitochondria.fasta",
		ref10 = RRNA+"/Plastids.fasta",
		ref11 = RRNA+"/Eukaryota.fasta",
		ref12 = REFERENCES+"/MH165324.fasta",
		ref13 = REFERENCES+"/HM059793_rubiscolargechloroplast.fasta"
	output:
		clean = CLEAN+"/{SAMPLES}_R1.fastq.gz",
		conta = CLEAN+"/conta/{SAMPLES}_R1.fastq.gz",
		statistic = CLEAN+"/{SAMPLES}_R1_stat"
	conda:
		ENVS
	shell:
		"""
		bbduk.sh -Xmx20g in={input.file} out={output.clean} outm={output.conta} stats={output.statistic} ref={input.ref1},{input.ref2},{input.ref3},{input.ref4},{input.ref5},{input.ref6},{input.ref7},{input.ref8},{input.ref9},{input.ref10},{input.ref11},{input.ref12},{input.ref13}
		"""

rule bbmap1:
	input:
		file = CLEAN+"/{SAMPLES}_R1.fastq.gz"
	output:
		clean = SUPERCLEAN+"/{SAMPLES}_R1.fastq.gz",
		conta = SUPERCLEAN+"/conta/{SAMPLES}_R1.fastq.gz",
		statistic = SUPERCLEAN+"/{SAMPLES}_R1_stat"
	conda:
		ENVS	
	shell:
		"""
		bbduk.sh -Xmx20g in={input.file} out={output.clean} outm={output.conta} stats={output.statistic} \
		literal=CTAATACGACTCACTATAGGGCAAGCAGTGGTATCAACGCAGAGT copyundefined k=25 hdist=2 mm=f
		"""
rule bbmap2:
	input:
		file1 = SUPERCLEAN+"/SRR066373_R1.fastq.gz",
		file2 = SUPERCLEAN+"/SRR1311174_R1.fastq.gz",
		file3 = SUPERCLEAN+"/SRR066374_R1.fastq.gz",
		file4 = SUPERCLEAN+"/SRR1311175_R1.fastq.gz",
		file5 = SUPERCLEAN+"/SRR342350_R1.fastq.gz",
		file6 = SUPERCLEAN+"/SRR342351_R1.fastq.gz",
		file7 = SUPERCLEAN+"/SRR066375_R1.fastq.gz",
		file8 = SUPERCLEAN+"/SRR1311176_R1.fastq.gz",
		file9 = SUPERCLEAN+"/SRR066376_R1.fastq.gz",
		file10 = SUPERCLEAN+"/SRR1311177_R1.fastq.gz",
	output:
		clean1 = SUPERSUPERCLEAN+"/SRR066373_R1.fastq.gz",
		stat1 = SUPERSUPERCLEAN+"/SRR066373_R1_stat",
		clean2 = SUPERSUPERCLEAN+"/SRR1311174_R1.fastq.gz",
		stat2 = SUPERSUPERCLEAN+"/SRR1311174_R1_stat",
		clean3 = SUPERSUPERCLEAN+"/SRR066374_R1.fastq.gz",
		stat3 = SUPERSUPERCLEAN+"/SRR066374_R1_stat",
		clean4 = SUPERSUPERCLEAN+"/SRR1311175_R1.fastq.gz",
		stat4 = SUPERSUPERCLEAN+"/SRR1311175_R1_stat",
		clean5 = SUPERSUPERCLEAN+"/SRR342350_R1.fastq.gz",
		stat5 = SUPERSUPERCLEAN+"/SRR342350_R1_stat",
		clean6 = SUPERSUPERCLEAN+"/SRR342351_R1.fastq.gz",
		stat6 = SUPERSUPERCLEAN+"/SRR342351_R1_stat",
		clean7 = SUPERSUPERCLEAN+"/SRR066375_R1.fastq.gz",
		stat7 = SUPERSUPERCLEAN+"/SRR066375_R1_stat",
		clean8 = SUPERSUPERCLEAN+"/SRR1311176_R1.fastq.gz",
		stat8 = SUPERSUPERCLEAN+"/SRR1311176_R1_stat",
		clean9 = SUPERSUPERCLEAN+"/SRR066376_R1.fastq.gz",
		stat9 = SUPERSUPERCLEAN+"/SRR066376_R1_stat",
		clean10 = SUPERSUPERCLEAN+"/SRR1311177_R1.fastq.gz",
		stat10 = SUPERSUPERCLEAN+"/SRR1311177_R1_stat"
	conda:
		ENVS
	shell:
		"""
		bbduk.sh in={input.file1} out={output.clean1} stats={output.stat1} ftr=310
		bbduk.sh in={input.file2} out={output.clean2} stats={output.stat2} ftr=520
		bbduk.sh in={input.file3} out={output.clean3} stats={output.stat3} ftr=520
		bbduk.sh in={input.file4} out={output.clean4} stats={output.stat4} ftr=310
		bbduk.sh in={input.file5} out={output.clean5} stats={output.stat5} ftr=310
		bbduk.sh in={input.file6} out={output.clean6} stats={output.stat6} ftr=280
		bbduk.sh in={input.file7} out={output.clean7} stats={output.stat7} ftr=520
		bbduk.sh in={input.file8} out={output.clean8} stats={output.stat8} ftr=520
		bbduk.sh in={input.file9} out={output.clean9} stats={output.stat9} ftr=310
		bbduk.sh in={input.file10} out={output.clean10} stats={output.stat10} ftr=520
		"""

rule fastqc_clean:
	input:
		SUPERSUPERCLEAN+"/{SAMPLES}.fastq.gz"
	output:
		zip = QC3+"/{SAMPLES}_fastqc.zip",
		html = QC3+"/{SAMPLES}_fastqc.html"
	conda:
		ENVS
	log:
		LOGS+"/fastqc_clean/{SAMPLES}"
	params:
		QC3
	shell:
		"""
		fastqc -o {params} --threads 2 {input}
		2> {log}
		"""

rule multiqc_clean:
	input:
		expand(QC3+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS)
	output:
		MULTIQC3+"/multiqc_report.html"
	conda:
		ENVS
	log:
		LOGS+"/multiqc_clean_qc/multiqc_report"
	params:
		indir = QC3 ,
		outdir = MULTIQC3
	shell:
		"""
		multiqc {params.indir} -o {params.outdir}
		2> {log}
		"""

rule star_mapping:
	input:
		file = SUPERSUPERCLEAN+"/{SAMPLES}_R1.fastq.gz",
		index = directory(DIR+"/index"),
	output:
		out1 = MAPPED+"/{SAMPLES}Aligned.sortedByCoord.out.bam",
		out2 = MAPPED+"/{SAMPLES}Log.final.out",
		out3 = MAPPED+"/{SAMPLES}Log.out",
		out4 = MAPPED+"/{SAMPLES}Log.progress.out",
		out5 = MAPPED+"/{SAMPLES}SJ.out.tab"
	conda:
		ENVS
	log:
		LOGS+"/star_mapping/{SAMPLES}",
	params:
		bam = directory(MAPPED),
		outfile = MAPPED+"/{SAMPLES}"
	shell:
		"""
		mkdir --parents {params.bam} &&
		STAR --runThreadN 8 \
		--genomeDir {input.index} \
		--readFilesIn {input.file} \
		--readFilesCommand gunzip -c \
		--outFileNamePrefix {params.outfile} \
		--outSAMtype BAM SortedByCoordinate \
		--alignIntronMax 10000 \
		--outFilterScoreMinOverLread 0.8 \
		--outSJfilterCountUniqueMin 5 1 1 1 \
		--outSJfilterOverhangMin 35 20 20 20 \
		--outSAMstrandField intronMotif \
		--outFilterIntronMotifs RemoveNoncanonical \
		> {log}
		"""

rule multiqc_star:
	input:
		expand(MAPPED+"/{SAMPLE}Log.final.out", SAMPLE=SAMPLES)
	output:
		MULTIQC4+"/multiqc_report.html"
	conda:
		ENVS
	log:
		LOGS+"/multiqc_star/multiqc_report"
	params:
		indir = MAPPED ,
		outdir = MULTIQC4
	shell:
		"""
		multiqc {params.indir} -o {params.outdir}
		2> {log}
		"""

rule multiqc_all:
	input:
		trimmed = expand(QC2+"/{SAMPLE}_{READ}_fastqc.html", SAMPLE=SAMPLES, READ=READS),
		clean = expand(SUPERSUPERCLEAN+"/{SAMPLE}_{READ}_stat", SAMPLE=SAMPLES, READ=READS),
		mapped = expand(MAPPED+"/{SAMPLE}Log.final.out", SAMPLE=SAMPLES, READ=READS),
	output:
		MULTIQC5+"/multiqc_report.html"
	conda:
		ENVS
	log:
		LOGS+"/multiqc_all/multiqc_report"
	params:
		indir1 = QC2 ,
		indir2 = CLEAN ,
		indir3 = MAPPED ,
		outdir = MULTIQC5
	shell:
		"""
		multiqc {params.indir1} {params.indir2} {params.indir3} -o {params.outdir}
		"""

rule cufflink:
	input:
		MAPPED+"/{SAMPLES}Aligned.sortedByCoord.out.bam"
	output:
		CUFFLINK+"/{SAMPLES}/transcripts.gtf"
	conda:
		ENVS
	log:
		LOGS+"/cufflink/{SAMPLES}"
	params:
		CUFFLINK+"/{SAMPLES}"
	shell:
		"""
		cufflinks -I 10000 --output-dir {params} {input} \
		> {log}
		"""

rule compose_merge:
	input:
		expand(CUFFLINK+"/{SAMPLE}/transcripts.gtf", SAMPLE=SAMPLES),
	output:
		txt=CUFFLINK+"/assemblies.txt"
	conda:
		ENVS
	log:
		LOGS+"/compare_merge.log"
	run:
		with open(output.txt, "w") as out: print(*input, sep="\n", file=out)
